{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8peXHyqqm5ge"
   },
   "source": [
    "# 午後の紅茶さん_Mistral\n",
    "\n",
    "\n",
    "RTX-4090 実行: 2024/9/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Sep 15 08:33:27 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 546.80       CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090 L...    On | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   50C    P8                5W /  55W|    134MiB / 16376MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/atsu/llamaindex\n",
      "/home/atsu/llamaindex/SadTalker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atsu/anaconda3/envs/llamaindex/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../\n",
    "%cd SadTalker\n",
    "# %ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Whisperのinstal --> 一度だけ実行\n",
    "# !pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid # 追加\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import gradio as gr\n",
    "import io\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import openai\n",
    "from huggingface_hub import login\n",
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from llama_index import GPTVectorStoreIndex, SimpleDirectoryReader, LLMPredictor, ServiceContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用した画像を削除してしまうので以下のコードをコメントアウトした。  \n",
    "shutil.move(source_image, input_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SadTalker用\n",
    "# from src.gradio_demo2 import SadTalker\n",
    "from inference6 import make_video # face_enhancer, background_enhancer 対応"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "playsound is relying on another python subprocess. Please use `pip install pygobject` if you want playsound to run more efficiently.\n"
     ]
    }
   ],
   "source": [
    "# VOICEVOX 用\n",
    "from pathlib import Path\n",
    "import voicevox_core\n",
    "from voicevox_core import AccelerationMode, AudioQuery, VoicevoxCore\n",
    "from playsound import playsound\n",
    "from pydub import AudioSegment\n",
    "# from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本パラメータ\n",
    "model_id = \"tokyotech-llm/Swallow-MS-7b-instruct-v0.1\"\n",
    "peft_name = \"../付喪神ジェネレータ/QLoRA_models/tea_mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI API ログイン\n",
    "from openai import OpenAI\n",
    "with open('../API_key/OpenAI_API_key.txt', 'r') as f:\n",
    "    key = f.read()\n",
    "os.environ[\"OPENAI_API_KEY\"] = key\n",
    "openai.api_key = key\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0ag7qhpfaZL"
   },
   "source": [
    "# Gradioを用いたWebアプリ作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 音声からテキストへの変換関数（新バージョン）\n",
    "# https://platform.openai.com/docs/guides/speech-to-text/quickstart\n",
    "def speech_to_text_API(input_audio):\n",
    "    audio_file = open(input_audio, \"rb\")\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "        model=\"whisper-1\", \n",
    "        file=audio_file,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOICEVOX によるテキストから音声変換\n",
    "def VOICEVOX(text, out='output.wav', SPEAKER_ID=2):\n",
    "    open_jtalk_dict_dir = './open_jtalk_dic_utf_8-1.11'\n",
    "    acceleration_mode = AccelerationMode.AUTO\n",
    "    core = VoicevoxCore(\n",
    "        acceleration_mode=acceleration_mode, open_jtalk_dict_dir=open_jtalk_dict_dir\n",
    "    )\n",
    "    core.load_model(SPEAKER_ID)\n",
    "    audio_query = core.audio_query(text, SPEAKER_ID)\n",
    "    wav = core.synthesis(audio_query, SPEAKER_ID)\n",
    "    out_byte = Path(out) # 追加\n",
    "    out_byte.write_bytes(wav)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3becdae3314f57ac7de6e6ffe48e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# モデルとトークナイザの準備\n",
    "# 量子化設定\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "# モデルの設定\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    # token=token, # HuggingFaceにログインしておけば不要\n",
    "    quantization_config=bnb_config, # 量子化\n",
    "    device_map='auto',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "# tokenizerの設定\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    padding_side=\"right\",\n",
    "    add_eos_token=True\n",
    ")\n",
    "if tokenizer.pad_token_id is None:\n",
    "  tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.27 s, sys: 349 ms, total: 3.62 s\n",
      "Wall time: 1.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ファインチューニングモデルの作成\n",
    "model = PeftModel.from_pretrained(base_model, peft_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章生成関数（EZO用）--> Llama3.1でもこのコードは有効だと分かった\n",
    "def generate(prompt, max_tokens=256, temperature=1, top_p=0.9, top_k=30):\n",
    "\n",
    "    prompt = f\"\"\"system prompt:あなたは午後の紅茶を飲むユーザーと対話するAIです。お嬢さま口調で対話してください。短く返答してください。\n",
    "    user prompt: {prompt}\"\"\"\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=max_tokens,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=temperature,\n",
    "        top_p=top_p,\n",
    "        top_k=top_k,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        attention_mask=torch.ones(input_ids.shape, dtype=torch.long).to(model.device),\n",
    "    )\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    response_text = tokenizer.decode(response, skip_special_tokens=True)\n",
    "    return response_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_response(input_mode, input_text, input_audio, image, voice, size, preprocess, face_enhancer, bkgnd_enhancer, \n",
    "                     max_tokens, temperature, top_p, top_k):\n",
    "    \n",
    "    # GPUメモリをリセット\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    if input_mode == \"Text\":\n",
    "        input_text = input_text\n",
    "    else:\n",
    "        input_text = speech_to_text_API(input_audio)\n",
    "\n",
    "    # GPUメモリをリセット\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 応答\n",
    "    code_regex = re.compile('[!\"#$%&\\'\\\\\\\\()*+,-./:;<=>?@[\\\\]^_`{|}~「」〔〕“”〈〉『』【】＆＊・（）＄＃＠！｀ 　＋￥％？ξﾟ⊿abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789]')\n",
    "    response_text = code_regex.sub('', generate(input_text, max_tokens, temperature, top_p, top_k)).replace(\"\\n\",\"\")\n",
    "    print(\"origilal response:\", response_text) \n",
    "    \n",
    "    print(\"===============================\")\n",
    "    print(\"processed response text: \" + response_text)\n",
    "\n",
    "    # GPUメモリをリセット\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 返答を音声に\n",
    "    out = \"../付喪神ジェネレータ/results/output.wav\"\n",
    "    if voice==\"四国めたんノーマル\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=2) #四国めたんノーマル\n",
    "    elif voice==\"四国めたんあまあま\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=0) #四国めたんあまあま\n",
    "    elif voice==\"四国めたんツンツン\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=6) #四国めたんツンツン\n",
    "    elif voice==\"四国めたんセクシー\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=4) #四国めたんセクシー\n",
    "    elif voice==\"波音リツ\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=9) #波音リツノーマル \n",
    "    elif voice==\"冥鳴ひまり\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=14) #冥鳴ひまりノーマル\n",
    "    elif voice==\"雨晴はう\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=10) #雨晴はうノーマル\n",
    "    elif voice==\"春日部つむぎ\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=8) #春日部つむぎノーマル\n",
    "    elif voice==\"九州そらノーマル\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=16) #九州そらノーマル\n",
    "    elif voice==\"九州そらあまあま\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=15) #九州そらあまあま\n",
    "    elif voice==\"九州そらツンツン\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=18) #九州そらツンツン\n",
    "    elif voice==\"九州そらセクシー\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=17) #九州そらセクシー\n",
    "    elif voice==\"九州そらささやき\":\n",
    "        response_audio = VOICEVOX(text=response_text, out=out, SPEAKER_ID=19) #九州そらささやき\n",
    "    \n",
    "    print(\"Sound generation finished.\") # ターミナルに表示\n",
    "    print(response_audio)\n",
    "\n",
    "    # 画像パスを引数に変更\n",
    "    image_path = image\n",
    "    print(image_path)\n",
    "    \n",
    "    # 追加のデバッグメッセージ\n",
    "    print(f\"Selected image path: {image_path}\")\n",
    "    if not os.path.isfile(image_path):\n",
    "        raise ValueError(f\"Image file does not exist: {image_path}\")\n",
    "    else:\n",
    "        print(f\"Image file exists: {image_path}\")\n",
    "\n",
    "    result_dir = '../付喪神ジェネレータ/results'\n",
    "    \n",
    "    # ファイルパスのデバッグメッセージを追加\n",
    "    print(f\"Pic path before test call: {os.path.join(result_dir, str(uuid.uuid4()), 'input', os.path.basename(image_path))}\")\n",
    "\n",
    "    responce_video = make_video(image_path=image_path,\n",
    "                                audio_path=response_audio,\n",
    "                                size=size,\n",
    "                                preprocess=preprocess,\n",
    "                                enhancer=face_enhancer,\n",
    "                                background_enhancer=bkgnd_enhancer,\n",
    "                                result_dir=result_dir,\n",
    "                                )\n",
    "    \n",
    "    print(\"Video generation finished.\") # ターミナルに表示\n",
    "    print(responce_video)\n",
    "\n",
    "    # GPUメモリをリセット\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # return rag_result, responce_video, voice, image_path\n",
    "    return responce_video, voice, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blockの定義\n",
    "# https://note.com/npaka/n/n2a5112208b8d\n",
    "\n",
    "# CSSを使用してボタンのスタイルをカスタマイズ\n",
    "css = \"\"\"\n",
    "#custom-button {\n",
    "    background: #ee7800; /* ボタンの背景色 */\n",
    "    color: white; /* ボタンのテキスト色 */\n",
    "    border: none;\n",
    "    text-align: center;\n",
    "    font-size: 20px;\n",
    "    cursor: pointer;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with gr.Blocks(css=css) as app:\n",
    "\n",
    "    # Markdow\n",
    "    gr.Markdown(\"\"\"# 超未来の付喪神ジェネレータ　午後の紅茶さん\"\"\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1, min_width=300):\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    with gr.Row():\n",
    "                        with gr.Column():\n",
    "                            input_mode = gr.Radio([\"Text\",\"Voice\"], label=\"Input mode\", value=\"Text\")\n",
    "                            input_text = gr.Textbox(placeholder=\"Please write the input.\", label=\"input text\",)\n",
    "                            record = gr.Audio(sources=[\"microphone\"], label=\"Input audio\", type=\"filepath\")\n",
    "                            voice = gr.Dropdown([\"random\", \"四国めたんノーマル\", \"四国めたんあまあま\", \"四国めたんツンツン\", \"四国めたんセクシー\",\n",
    "                                                 \"波音リツ\", \"冥鳴ひまり\", \"雨晴はう\", \"春日部つむぎ\",\n",
    "                                                 \"九州そらノーマル\", \"九州そらあまあま\", \"九州そらツンツン\",\n",
    "                                                 \"九州そらセクシー\", \"九州そらささやき\"],\n",
    "                                                 label=\"voice\", value=\"春日部つむぎ\")\n",
    "                            clear = gr.ClearButton(components=[record])\n",
    "                        with gr.Column():\n",
    "                            image = gr.Image(type='filepath') #画像のpathを返す\n",
    "                            clear = gr.ClearButton(components=[image])\n",
    "            with gr.Row():\n",
    "                btn = gr.Button(\"Response\", elem_id=\"custom-button\") #ボタンにIDを指定\n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=1):                        \n",
    "                    with gr.Row():\n",
    "                        gr.Markdown(\"LLM congig\")\n",
    "                        max_tokens = gr.Dropdown([32, 64, 128, 256, 512, 1024, 2048, 4096, 8192], label=\"max tokens\", value=64)\n",
    "                        temperature = gr.Slider(minimum=0.01, maximum=1, value=1, step=0.01, label=\"temperature\", interactive=True)\n",
    "                        top_p = gr.Slider(minimum=0, maximum=1, value=0.9, step=0.01, label=\"top_p\", interactive=True)\n",
    "                        top_k = gr.Slider(minimum=1, maximum=100, value=30, step=1, label=\"top_k\", interactive=True)\n",
    "                with gr.Column(scale=1):\n",
    "                    gr.Markdown(\"SadTalker congig\")\n",
    "                    with gr.Row():\n",
    "                        preprocess = gr.Dropdown([\"crop\", \"extcrop\", \"resize\", \"full\", \"extfull\"], label=\"preprocess\", value=\"extcrop\")\n",
    "                        size = gr.Dropdown([256, 512], label=\"image size\", value=256)\n",
    "                        face_enhancer = gr.Dropdown([None, \"gfpgan\", \"RestoreFormer\"], label=\"face enhancer\", value=None)\n",
    "                        bkgnd_enhancer = gr.Dropdown([None, \"realesrgan\"], label=\"background enhancer\", value=None)\n",
    "            with gr.Row():\n",
    "                # rag_result = gr.Text(label=\"RAG result\")\n",
    "                agent_voice = gr.Text(label=\"Voice of agent\")\n",
    "                agent_image = gr.Text(label=\"Image of agent\")                \n",
    "        with gr.Column(scale=1, min_width=300):\n",
    "            response_video = gr.Video(label=\"Response video\")\n",
    "            # イベントリスナー\n",
    "            btn.click(fn=overall_response,\n",
    "                      inputs=[input_mode, input_text, record, image, voice, \n",
    "                              size, preprocess, face_enhancer, bkgnd_enhancer, max_tokens, temperature, top_p, top_k],                   \n",
    "                      outputs=[response_video, agent_voice, agent_image]\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://1c210eb8558bc5b4fb.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://1c210eb8558bc5b4fb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origilal response: ワタクシ思いますの、午後の紅茶、いい響きですわねー。お茶を淹れるためのお道具は、ワタクシのコレクションの中で最も愛着のあるものの一つでごわー。淹れるお茶の種類は、その日の気分\n",
      "===============================\n",
      "processed response text: ワタクシ思いますの、午後の紅茶、いい響きですわねー。お茶を淹れるためのお道具は、ワタクシのコレクションの中で最も愛着のあるものの一つでごわー。淹れるお茶の種類は、その日の気分\n",
      "Sound generation finished.\n",
      "../付喪神ジェネレータ/results/output.wav\n",
      "/tmp/gradio/a1a1932be42492edbad21dde28837a48d1d1462e/tea_girl.png\n",
      "Selected image path: /tmp/gradio/a1a1932be42492edbad21dde28837a48d1d1462e/tea_girl.png\n",
      "Image file exists: /tmp/gradio/a1a1932be42492edbad21dde28837a48d1d1462e/tea_girl.png\n",
      "Pic path before test call: ../付喪神ジェネレータ/results/c9e55da5-e88c-4769-afc2-6a679a5a0621/input/tea_girl.png\n",
      "using safetensor as default\n",
      "3DMM Extraction for source image\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "landmark Det:: 100%|██████████████████████████████████████| 1/1 [00:00<00:00,  2.71it/s]\n",
      "3DMM Extraction In Video:: 100%|██████████████████████████| 1/1 [00:00<00:00, 19.88it/s]\n",
      "mel:: 100%|████████████████████████████████████████| 351/351 [00:00<00:00, 98016.03it/s]\n",
      "audio2exp:: 100%|██████████████████████████████████████| 36/36 [00:00<00:00, 231.23it/s]\n",
      "Face Renderer:: 100%|█████████████████████████████████| 176/176 [02:15<00:00,  1.30it/s]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The generated video is named ../付喪神ジェネレータ/results/2024_09_15_08.41.35/tea_girl##output.mp4\n",
      "Video generation finished.\n",
      "../付喪神ジェネレータ/results/2024_09_15_08.41.35.mp4\n"
     ]
    }
   ],
   "source": [
    "# Webアプリを起動\n",
    "app.launch(share=True, debug=True) # share=Trueで一時的に公開される"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNz/sMhizLOoO3w2ZAVjkv7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
